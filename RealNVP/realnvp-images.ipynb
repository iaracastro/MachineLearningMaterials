{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms, utils\n",
    "from torch.nn.utils.parametrizations import weight_norm\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets.CIFAR10('data', train=True, download=True,\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "]))\n",
    "\n",
    "test_dataset = datasets.CIFAR10('data', train=False, download=True,\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspired by https://github.com/bjlkeng/sandbox/blob/master/realnvp/pytorch-realnvp-cifar10.ipynb\n",
    "check_mask = {}\n",
    "check_mask_device = {}\n",
    "# Partitions the input image into two sets of variables\n",
    "def partition_mask(shape, to_device=True):\n",
    "    global check_mask, check_mask_device\n",
    "    if shape not in check_mask:\n",
    "        check_mask[shape] = 1 - np.indices(shape).sum(axis=0) % 2 \n",
    "        check_mask[shape] = torch.Tensor(check_mask[shape])\n",
    "        \n",
    "    if to_device and shape not in check_mask_device:\n",
    "        check_mask_device[shape] = check_mask[shape].to(device)\n",
    "        \n",
    "    return check_mask_device[shape] if to_device else check_mask[shape]\n",
    "\n",
    "\n",
    "chan_mask = {}\n",
    "chan_mask_device = {}\n",
    "# Segregrates the channels into two groups, which transformations are independently applied\n",
    "def channel_mask(shape, to_device=True):\n",
    "    assert len(shape) == 3, shape\n",
    "    assert shape[0] % 2 == 0, shape\n",
    "    global chan_mask, chan_mask_device\n",
    "    if shape not in chan_mask:\n",
    "        chan_mask[shape] = torch.cat([torch.zeros((shape[0] // 2, shape[1], shape[2])),\n",
    "                                      torch.ones((shape[0] // 2, shape[1], shape[2])),],\n",
    "                                      dim=0)\n",
    "        assert chan_mask[shape].shape == shape, (chan_mask[shape].shape, shape)\n",
    "        \n",
    "    if to_device and shape not in chan_mask_device:\n",
    "        chan_mask_device[shape] = chan_mask[shape].to(device)\n",
    "        \n",
    "    return chan_mask_device[shape] if to_device else chan_mask[shape]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class for Normalizing Flows with Real NVP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv1 = weight_norm(nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=1, padding=1, bias=False))\n",
    "        self.bn1 = nn.BatchNorm2d(out_planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = weight_norm(nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1, padding=1, bias=False))\n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        return out + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalizingFlow_NVP(nn.Module):\n",
    "    def __init__(self, num_coupling=6, num_final_coupling=4, planes=64, shape=(3,32,32)):\n",
    "        super(NormalizingFlow, self).__init__()\n",
    "        self.num_coupling = num_coupling # Number of initial coupling layers\n",
    "        self.num_final_coupling = num_final_coupling # Number of final coupling layers\n",
    "        self.shape = shape # Shape of the input image\n",
    "        \n",
    "        self.planes = planes # Number of output planes in the convolutional layers\n",
    "        self.s = nn.ModuleList() # Scaling functions for each coupling layer\n",
    "        self.t = nn.ModuleList() # Translation functions for each coupling layer \n",
    "        self.norms = nn.ModuleList() # List of batch normalization layers \n",
    "        \n",
    "        # Learnable scalar scaling parameters for outputs of s and t\n",
    "        self.s_scale = nn.ParameterList()\n",
    "        self.t_scale = nn.ParameterList()\n",
    "        self.t_bias = nn.ParameterList()\n",
    "        self.shapes = []\n",
    "        \n",
    "        # A common stack of convolutional blocks used in s and t functions\n",
    "        self.conv_stack = nn.Sequential(\n",
    "            weight_norm(nn.Conv2d(3, planes, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            nn.BatchNorm2d(planes),\n",
    "            ConvBlock(planes, shape[0]),\n",
    "            ConvBlock(planes, shape[0]),\n",
    "            ConvBlock(planes, shape[0]),\n",
    "            ConvBlock(planes, shape[0]),\n",
    "            weight_norm(nn.Conv2d(3, planes, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            nn.BatchNorm2d(planes),\n",
    "        )\n",
    "      \n",
    "        shape = self.shape\n",
    "        for i in range(num_coupling):\n",
    "            self.append_transformations(shape)\n",
    "           # Change shape and planes to increase model's capacity\n",
    "            if i % 6 == 2:\n",
    "                shape = (4 * shape[0], shape[1] // 2, shape[2] // 2)\n",
    "            if i % 6 == 5:\n",
    "                # Factoring out half the channels\n",
    "                shape = (shape[0] // 2, shape[1], shape[2])\n",
    "                planes = 2 * planes\n",
    "       \n",
    "        # Setup final coupling layers with possibly different configurations\n",
    "        for i in range(num_final_coupling):\n",
    "            self.append_transformations(shape)\n",
    "           \n",
    "        self.validation = False # Flag to indicate if the model is in validation mode\n",
    "    \n",
    "    def append_transformations(self, shape: int):\n",
    "        self.s.append(self.conv_stack)\n",
    "        self.t.append(self.conv_stack)\n",
    "        self.s_scale.append(torch.nn.Parameter(torch.zeros(shape), requires_grad=True))\n",
    "        self.t_scale.append(torch.nn.Parameter(torch.zeros(shape), requires_grad=True))\n",
    "        self.t_bias.append(torch.nn.Parameter(torch.zeros(shape), requires_grad=True)) \n",
    "        self.norms.append(nn.BatchNorm2d(shape[0]))\n",
    "        self.shapes.append(shape)\n",
    "\n",
    "    def validate(self):\n",
    "        # Set the model to validation mode\n",
    "        self.eval()\n",
    "        self.validation = True\n",
    "\n",
    "    def train(self, mode=True):\n",
    "        # Set the model to training mode\n",
    "        nn.Module.train(self, mode)\n",
    "        self.validation = False\n",
    "\n",
    "    def get_binary_mask(self, shape: int, i: int):\n",
    "        # Apply mask to manage which parts of the data are transformed\n",
    "        if i in range(self.num_coupling):\n",
    "            binary_mask = partition_mask(shape) if i % 6 < 3 else channel_mask(shape)\n",
    "        else:\n",
    "            binary_mask = partition_mask(shape)\n",
    "        return  binary_mask if i % 2 == 0 else (1 - binary_mask)\n",
    "\n",
    "    def set_transformation(self, is_reverse: True, b: torch.Tensor, input_tensor: torch.Tensor, layer_i: int):\n",
    "        # Compute scaling and translation functions for each coupling layer\n",
    "        s = (self.s_scale[layer_i]) * torch.tanh(self.s[layer_i](b * x))\n",
    "        t = (self.t_scale[layer_i]) * self.t[layer_i](b * x) + (self.t_bias[layer_i])\n",
    "        # Apply transformation\n",
    "        if not reverse:\n",
    "            x = input_tensor \n",
    "            return b * x + (1 - b) * (x * torch.exp(s) + t), s, t\n",
    "        else:\n",
    "            y = input_tensor \n",
    "            return b * y + (1 - b) * ((y - t) * torch.exp(-s))\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # Forward pass through the normalizing flow model\n",
    "        if self.training or self.validation:\n",
    "            # List to collect scaling outputs  / batch normalizaiton layers / outputs from each coupling layer\n",
    "            s_vals = [] \n",
    "            norm_vals = [] \n",
    "            y_vals = [] \n",
    "\n",
    "            # Process through each coupling layer\n",
    "            for i in range(self.num_coupling):\n",
    "                shape = self.shapes[i]\n",
    "\n",
    "                b_mask = self.get_binary_mask(shape, i)\n",
    "                y, s, _ = self.set_transformation(b_mask, x, i)\n",
    "                s_vals.append(torch.flatten((1 - b_mask) * s))\n",
    "\n",
    "                # Apply batch normalization if available and collect outputs\n",
    "                if self.norms[i] is not None:\n",
    "                    y, norm_loss = self.norms[i](y, validation=self.validation)\n",
    "                    norm_vals.append(norm_loss)\n",
    "\n",
    "                # Update shape for pixel operations\n",
    "                if i % 6 == 2:\n",
    "                    y = torch.nn.functional.pixel_unshuffle(y, 2)\n",
    "\n",
    "                # Manage channel factors for dimension management\n",
    "                if i % 6 == 5:\n",
    "                    factor_channels = y.shape[1] // 2\n",
    "                    y_vals.append(torch.flatten(y[:, factor_channels:, :, :], 1))\n",
    "                    y = y[:, :factor_channels, :, :]\n",
    "\n",
    "                x = y\n",
    "\n",
    "            # Apply final coupling layers\n",
    "            for i in range(self.num_coupling, self.num_coupling + self.num_final_coupling):\n",
    "                shape = self.shapes[i]\n",
    "                b_mask = self.get_binary_mask(shape, i)\n",
    "                y, s, _ = self.set_transformation(b_mask, x, i)\n",
    "                s_vals.append(torch.flatten((1 - b_mask) * s))\n",
    "\n",
    "                if self.norms[i] is not None:\n",
    "                    y, norm_loss = self.norms[i](y, validation=self.validation)\n",
    "                    norm_vals.append(norm_loss)\n",
    "\n",
    "                x = y\n",
    "\n",
    "            y_vals.append(torch.flatten(y, 1))\n",
    "\n",
    "            # Aggregate outputs and various losses for determinant computation\n",
    "            return (torch.flatten(torch.cat(y_vals, 1), 1),\n",
    "                    torch.cat(s_vals), \n",
    "                    torch.cat([torch.flatten(v) for v in norm_vals]) if len(norm_vals) > 0 else torch.zeros(1),\n",
    "                    torch.cat([torch.flatten(s) for s in self.s_scale]))\n",
    "        else:\n",
    "            # Reverse transformation for data generation\n",
    "            y = x\n",
    "            y_remaining = y\n",
    "\n",
    "            layer_vars = np.prod(self.shapes[-1])\n",
    "            y = torch.reshape(y_remaining[:, -layer_vars:], (-1,) + self.shapes[-1])\n",
    "            y_remaining = y_remaining[:, :-layer_vars]\n",
    "\n",
    "            # Reversed operations for final checkerboard and coupling layers\n",
    "            for i in reversed(range(self.num_coupling, self.num_coupling + self.num_final_coupling)):\n",
    "                if self.norms[i] is not None:\n",
    "                    y, _ = self.norms[i](y)\n",
    "              \n",
    "                shape = self.shapes[i]\n",
    "                b_mask = self.get_binary_mask(shape, i)\n",
    "                x = self.set_transformation(True, b_mask, y, i)\n",
    "                y = x           \n",
    "\n",
    "            # Prepate for multi-scale operations\n",
    "            layer_vars = np.prod(shape)\n",
    "            y = torch.cat((y, torch.reshape(y_remaining[:, -layer_vars:], (-1,) + shape)), 1)\n",
    "            y_remaining = y_remaining[:, :-layer_vars]\n",
    "\n",
    "            # Multi-scale coupling layers (Reverse transformations for earlier layers)\n",
    "            for i in reversed(range(self.num_coupling)):\n",
    "                shape = self.shapes[i]\n",
    "                b_mask = self.get_binary_mask(shape, i)\n",
    "\n",
    "                if self.norms[i] is not None:\n",
    "                    y, _ = self.norms[i](y)\n",
    "\n",
    "                x = self.set_transformation(True, b_mask, y, i)\n",
    "\n",
    "                if i % 6 == 3:\n",
    "                    x = torch.nn.functional.pixel_shuffle(x, 2)\n",
    "\n",
    "                y = x\n",
    "\n",
    "                if i > 0 and i % 6 == 0:\n",
    "                    layer_vars = np.prod(shape)\n",
    "                    y = torch.cat((y, torch.reshape(y_remaining[:, -layer_vars:], (-1,) + shape)), 1)\n",
    "                    y_remaining = y_remaining[:, :-layer_vars]\n",
    "\n",
    "            assert np.prod(y_remaining.shape) == 0\n",
    "            return x\n",
    "\n",
    "def loss_func(y, s, norms, scale, batch_size):\n",
    "    # -log(zero-mean gaussian) + log determinant\n",
    "    # -log p_x = log(pz(f(x))) + log(det(\\partial f/\\partial x))\n",
    "    # -log p_x = 0.5 * y**2 + s1 + s2 + ... + batch_norm_scalers + l2_regularizers(scale)\n",
    "\n",
    "    log_px = -torch.sum(0.5 * torch.log(2 * torch.tensor(np.pi)) + 0.5 * y ** 2) # priori gaussiana\n",
    "    determinant = torch.sum(s) \n",
    "    norms = torch.sum(norms)\n",
    "    reg = 5e-5 * torch.sum(scale ** 2) # regularization on scaling parameters\n",
    "    loss = -(log_px + determinant + norms) + reg \n",
    "    return torch.div(loss, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "continua essa estrutura abaixo, lembra que os dados já tão carregados lá em cima. Não printa tudo que nem o cara do notebook, a nossa função de loss só vai retornar a loss msm kkkk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pixels = 32*32*3\n",
    "\n",
    "def train_model(model, loss_func, optimizer, batch_size, report_iters=10):\n",
    "    \n",
    "\n",
    "def test_model(model, loss_func):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = \n",
    "batch_size = \n",
    "epochs = \n",
    "\n",
    "model = NormalizingFlow_NVP().to(device)\n",
    "optimizer = \n",
    "scheduler = \n",
    "\n",
    "for t in range(epochs):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.eval()\n",
    "with torch.no_grad():\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
