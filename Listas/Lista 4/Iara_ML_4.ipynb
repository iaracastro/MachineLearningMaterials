{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "435db6f4-e15b-4f9b-8cd0-b9b5dedd9e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from typing import Self\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a8837d-5164-4be5-9997-fdd0a687f07e",
   "metadata": {},
   "source": [
    "**Instruções gerais:** Sua submissão <u>deve</u> conter: \n",
    "1. Um \"ipynb\" com seu código e as soluções dos problemas\n",
    "2. Uma versão pdf do ipynb\n",
    "\n",
    "Caso você opte por resolver as questões de \"papel e caneta\" em um editor de $\\LaTeX$ externo, o inclua no final da versão pdf do 'ipynb'--- submetendo um <u>único pdf</u>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58678575-bb0a-4ff2-85d2-f1ff100806f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Trabalho de casa 04: Seleção de modelo e hiperparametros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af932776-d827-4ee8-b749-c1aec78faadf",
   "metadata": {},
   "source": [
    "**1.** O código abaixo carrega o banco de dados *California housing*. Divida o banco de dados em treino, teste e validação. Use o conjunto de validação para escolher o coeficiente de regularização $c$ para um modelo de regressão linear com penalização $L_2$. Use a fórmula analítica para estimar os pesos do modelo de regressão. Plote os MSE no conjunto de treino e validação em função de $c$. Comente o resultado. Avalie a performance do modelo ótimo no conjunto de teste e também comente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21701c8f-7d43-450e-9541-38aec817de0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0\n",
    "np.random.seed(SEED)\n",
    "\n",
    "X, y = fetch_california_housing(return_X_y=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=SEED\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0323d40-ffbc-4b85-a512-f0a979ed9e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regressão Linear com penalização L2 (Ridge Regression)\n",
    "class RidgeRegression:\n",
    "    def __init__(self, c: float) -> None:\n",
    "        self.c = c\n",
    "        self.theta: np.ndarray = None\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> Self:\n",
    "        n, m = X.shape\n",
    "        self.X = np.c_[np.ones((n, 1)), X]\n",
    "        I = np.eye(m + 1)\n",
    "        I[0, 0] = 0\n",
    "        # Use a fórmula analítica para estimar os pesos do modelo de regressão\n",
    "        self.theta = np.linalg.pinv(self.X.T @ self.X + self.c * I) @ self.X.T @ y\n",
    "        # self.theta = np.linalg.solve(self.X.T @ self.X + self.c * I, self.X.T @ y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        n = X.shape[0]\n",
    "        X = np.c_[np.ones((n, 1)), X]\n",
    "        return X @ self.theta\n",
    "\n",
    "# Calcula o erro quadrático médio\n",
    "def mse(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    return np.mean((y_true - y_pred) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bb671ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor coeficiente de regularização: 49.73895958790068\n"
     ]
    }
   ],
   "source": [
    "c_values = np.logspace(-5, 5, num=1000)\n",
    "best_mse = float('inf')\n",
    "best_c = None\n",
    "\n",
    "# Para cada valor de c, treina o modelo usando a penalização L2 e calcula o erro quadrático médio\n",
    "for c in c_values:\n",
    "    theta = RidgeRegression(c)\n",
    "    theta.fit(X_train, y_train)\n",
    "    y_pred = theta.predict(X_val)\n",
    "    error = mse(y_val, y_pred)\n",
    "    # Atualiza o melhor valor de c\n",
    "    if error < best_mse:\n",
    "        best_mse = error\n",
    "        best_c = c\n",
    "\n",
    "print(f'Melhor coeficiente de regularização: {best_c}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9724c93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plote os MSE no conjunto de trieno e validação em função de c.\n",
    "train_errors = []\n",
    "val_errors = []\n",
    "\n",
    "for c in c_values:\n",
    "    theta = RidgeRegression(c)\n",
    "    theta.fit(X_train, y_train)\n",
    "    y_pred_train = theta.predict(X_train)\n",
    "    y_pred_val = theta.predict(X_val)\n",
    "\n",
    "    train_errors.append(mse(y_train, y_pred_train))\n",
    "    val_errors.append(mse(y_val, y_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47abf862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(c_values, train_errors, label='Treino', color='blue')\n",
    "plt.plot(c_values, val_errors, label='Validação', color='orange')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Coeficiente de Regularização (c)')\n",
    "plt.xticks([1e-10, 1e-5, 1, 1e5, 1e10])\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.title('MSE no conjunto de treino e validação em função de c')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ffc681",
   "metadata": {},
   "source": [
    "Ao avaliar a performance do modelo ótimo no conjunto de teste, temos que:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "251e4402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mse com melhor c (49.73895958790068): 0.5387553011203188\n"
     ]
    }
   ],
   "source": [
    "class_ = RidgeRegression(best_c)\n",
    "class_.fit(X_train, y_train)\n",
    "\n",
    "y_test_pred = class_.predict(X_test)\n",
    "test_error = mse(y_test, y_test_pred)\n",
    "\n",
    "print(f'Mse com melhor c ({best_c}): {test_error}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462e0cf9",
   "metadata": {},
   "source": [
    "Podemos ver que o melhor coeficiente de regularização é $\\approx 49.16$ e o erro no conjunto de teste com esse coeficiente é $\\approx 0.538$. Pelo gráfico, quando $c$ continua a aumentar após esse ponto ótimo, o erro no conjunto de treino começa a aumentar. Isso é indicativo de que para valores muito altos de $c$, o modelo pode começar a sofrer de overfitting, o que significa que está começando a ser penalizado em excesso pela regularização, perdendo a capacidade de se ajustar bem até mesmo aos dados de treino. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f82119",
   "metadata": {},
   "source": [
    "## Questão 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54935fda-2b5b-462e-87fa-897e97408f29",
   "metadata": {},
   "source": [
    "**2.** Implemente 5-fold *nested cross-validation* para escolher entre os métodos $k$-NN e regressão linear com regularização $L_2$ (similar ao exercício acima). Considere $k \\in \\{1, 2, 3, 4, 5\\}$ e $c \\in \\{0, 1, 10, 100\\}$. Use o mesmo banco de dados do último exercício e comente o resultado. Em média, qual valor de hiperparametro resulta na melhor performance para o método escolhido (use 5-fold cross validation regular para isso)?\n",
    "\n",
    "Obs.: para simplificar sua vida, use o $k$-NN para regressão do scikit-learning com distância euclidiana.\n",
    "\n",
    "Obs. 2: para mais informações sobre o $K$-fold *nested cross-validation*, recomendamos esses materiais:\n",
    "- [Algoritmo e breve explicação](https://weina.me/nested-cross-validation): a autora apresenta uma boa explicação do assunto acompanhada de uma descrição do algoritmo;\n",
    "- [Ilustrações e explicação acompanhada de código](https://ploomber.io/blog/nested-cv/): ajuda a visualizar melhor o que é *nested cross-validation*; vale lembrar que seu código, diferente do dos exemplos desse link, não deve utilizar scikit-learn para implementar a *cross-validation*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c0c1a11-7e42-4f54-af38-c6cde8cf5b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KFold:\n",
    "    def __init__(\n",
    "        self, n_splits: int, seed: int | None = None\n",
    "    ) -> None:\n",
    "        # Número de divisões (folds)\n",
    "        self.n_splits = n_splits\n",
    "        self.seed = seed\n",
    "\n",
    "    def split(self, X: np.ndarray, y: np.ndarray):\n",
    "        n = X.shape[0]\n",
    "        np.random.seed(self.seed)\n",
    "        # Cria uma permutação aleatória dos índices\n",
    "        indices = np.random.permutation(n)\n",
    "        # Para cada divisão na validação cruzada\n",
    "        for i in range(self.n_splits):\n",
    "            # Calcula o índice de início e fim da divisão atual\n",
    "            start = i * n // self.n_splits\n",
    "            end = (i + 1) * n // self.n_splits\n",
    "\n",
    "            # Cria os índices de treino e validação\n",
    "            train = np.concatenate([indices[:start], indices[end:]])\n",
    "            validation = indices[start:end]\n",
    "\n",
    "            # Retorna os conjuntos de treino e validação\n",
    "            yield X[train], X[validation], y[train], y[validation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0daa9e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossValidation:\n",
    "    def __init__(\n",
    "        self, class_: type, parameters: list[float],\n",
    "        n_splits: int, seed: int | None = None, log_results: bool = False\n",
    "    ) -> None:\n",
    "        self.class_ = class_\n",
    "        self.parameters = parameters\n",
    "        self.n_splits = n_splits # Número de folds\n",
    "        self.seed = seed\n",
    "        self.log_results = log_results\n",
    "        # Cada valor terá um array com os erros de cada fold\n",
    "        self.errors: defaultdict[float, np.ndarray] = None\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> Self:\n",
    "        # Inicializa o dicionário de erros com arrays de zeros\n",
    "        default_constructor = lambda: np.zeros(self.n_splits)\n",
    "        self.errors = defaultdict(default_constructor)\n",
    "        # Cria um objeto KFold para a validação cruzada\n",
    "        kfold = KFold(self.n_splits, self.seed)\n",
    "\n",
    "        # Para cada fold, treina o modelo com cada parâmetro e calcula o erro\n",
    "        for i, (X_train, X_val, y_train, y_val) in enumerate(kfold.split(X, y)):\n",
    "            for value in self.parameters:\n",
    "                model = self.class_(value).fit(X_train, y_train)\n",
    "                y_pred = model.predict(X_val) # Faz a predição\n",
    "                error = mse(y_val, y_pred) # Calcula o erro\n",
    "                self.errors[value][i] += error # Adiciona o erro ao array do parâmetro\n",
    "\n",
    "                if self.log_results:\n",
    "                    print(f'Parâmetro: {value} - Fold {i + 1} - MSE: {error:.5f}')\n",
    "        return self\n",
    "\n",
    "    @property\n",
    "    def best_parameter(self):\n",
    "        # Retorna o parâmetro com o menor erro médio\n",
    "        return min(self.errors, key=lambda k: self.errors[k].mean())\n",
    "\n",
    "    @property\n",
    "    def best_model(self):\n",
    "        # Retorna o modelo com o melhor parâmetro\n",
    "        return self.class_(self.best_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6a076ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatena os conjuntos de treino e validação\n",
    "X_train = np.concatenate([X_train, X_val]) \n",
    "y_train = np.concatenate([y_train, y_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a57a9b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando a validação cruzada...\n",
      "Parâmetro: 1 - Fold 1 - MSE: 1.75532\n",
      "Parâmetro: 2 - Fold 1 - MSE: 1.41781\n",
      "Parâmetro: 3 - Fold 1 - MSE: 1.29262\n",
      "Parâmetro: 4 - Fold 1 - MSE: 1.23878\n",
      "Parâmetro: 5 - Fold 1 - MSE: 1.19658\n",
      "Parâmetro: 1 - Fold 2 - MSE: 1.65331\n",
      "Parâmetro: 2 - Fold 2 - MSE: 1.37090\n",
      "Parâmetro: 3 - Fold 2 - MSE: 1.26333\n",
      "Parâmetro: 4 - Fold 2 - MSE: 1.20202\n",
      "Parâmetro: 5 - Fold 2 - MSE: 1.18925\n",
      "Parâmetro: 1 - Fold 3 - MSE: 1.64711\n",
      "Parâmetro: 2 - Fold 3 - MSE: 1.34047\n",
      "Parâmetro: 3 - Fold 3 - MSE: 1.24270\n",
      "Parâmetro: 4 - Fold 3 - MSE: 1.19901\n",
      "Parâmetro: 5 - Fold 3 - MSE: 1.18478\n",
      "Parâmetro: 1 - Fold 4 - MSE: 1.72897\n",
      "Parâmetro: 2 - Fold 4 - MSE: 1.37842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parâmetro: 3 - Fold 4 - MSE: 1.27584\n",
      "Parâmetro: 4 - Fold 4 - MSE: 1.24874\n",
      "Parâmetro: 5 - Fold 4 - MSE: 1.24406\n",
      "Parâmetro: 1 - Fold 5 - MSE: 1.66751\n",
      "Parâmetro: 2 - Fold 5 - MSE: 1.31643\n",
      "Parâmetro: 3 - Fold 5 - MSE: 1.19303\n",
      "Parâmetro: 4 - Fold 5 - MSE: 1.15675\n",
      "Parâmetro: 5 - Fold 5 - MSE: 1.14222\n",
      "Modelo: KNeighborsRegressor - Fold: 1 - MSE: 1.17717\n",
      "\n",
      "Parâmetro: 1 - Fold 1 - MSE: 1.78848\n",
      "Parâmetro: 2 - Fold 1 - MSE: 1.38571\n",
      "Parâmetro: 3 - Fold 1 - MSE: 1.27794\n",
      "Parâmetro: 4 - Fold 1 - MSE: 1.24126\n",
      "Parâmetro: 5 - Fold 1 - MSE: 1.20836\n",
      "Parâmetro: 1 - Fold 2 - MSE: 1.68897\n",
      "Parâmetro: 2 - Fold 2 - MSE: 1.40651\n",
      "Parâmetro: 3 - Fold 2 - MSE: 1.30841\n",
      "Parâmetro: 4 - Fold 2 - MSE: 1.25722\n",
      "Parâmetro: 5 - Fold 2 - MSE: 1.23531\n",
      "Parâmetro: 1 - Fold 3 - MSE: 1.70898\n",
      "Parâmetro: 2 - Fold 3 - MSE: 1.35699\n",
      "Parâmetro: 3 - Fold 3 - MSE: 1.24524\n",
      "Parâmetro: 4 - Fold 3 - MSE: 1.17956\n",
      "Parâmetro: 5 - Fold 3 - MSE: 1.15081\n",
      "Parâmetro: 1 - Fold 4 - MSE: 1.71908\n",
      "Parâmetro: 2 - Fold 4 - MSE: 1.37988\n",
      "Parâmetro: 3 - Fold 4 - MSE: 1.28036\n",
      "Parâmetro: 4 - Fold 4 - MSE: 1.24625\n",
      "Parâmetro: 5 - Fold 4 - MSE: 1.22163\n",
      "Parâmetro: 1 - Fold 5 - MSE: 1.70841\n",
      "Parâmetro: 2 - Fold 5 - MSE: 1.38332\n",
      "Parâmetro: 3 - Fold 5 - MSE: 1.24517\n",
      "Parâmetro: 4 - Fold 5 - MSE: 1.20512\n",
      "Parâmetro: 5 - Fold 5 - MSE: 1.18386\n",
      "Modelo: KNeighborsRegressor - Fold: 2 - MSE: 1.12266\n",
      "\n",
      "Parâmetro: 1 - Fold 1 - MSE: 1.72272\n",
      "Parâmetro: 2 - Fold 1 - MSE: 1.37460\n",
      "Parâmetro: 3 - Fold 1 - MSE: 1.28364\n",
      "Parâmetro: 4 - Fold 1 - MSE: 1.22465\n",
      "Parâmetro: 5 - Fold 1 - MSE: 1.20042\n",
      "Parâmetro: 1 - Fold 2 - MSE: 1.66707\n",
      "Parâmetro: 2 - Fold 2 - MSE: 1.34209\n",
      "Parâmetro: 3 - Fold 2 - MSE: 1.24584\n",
      "Parâmetro: 4 - Fold 2 - MSE: 1.20308\n",
      "Parâmetro: 5 - Fold 2 - MSE: 1.18887\n",
      "Parâmetro: 1 - Fold 3 - MSE: 1.69736\n",
      "Parâmetro: 2 - Fold 3 - MSE: 1.29671\n",
      "Parâmetro: 3 - Fold 3 - MSE: 1.17307\n",
      "Parâmetro: 4 - Fold 3 - MSE: 1.13417\n",
      "Parâmetro: 5 - Fold 3 - MSE: 1.11981\n",
      "Parâmetro: 1 - Fold 4 - MSE: 1.71002\n",
      "Parâmetro: 2 - Fold 4 - MSE: 1.34999\n",
      "Parâmetro: 3 - Fold 4 - MSE: 1.26377\n",
      "Parâmetro: 4 - Fold 4 - MSE: 1.23511\n",
      "Parâmetro: 5 - Fold 4 - MSE: 1.22939\n",
      "Parâmetro: 1 - Fold 5 - MSE: 1.65337\n",
      "Parâmetro: 2 - Fold 5 - MSE: 1.31728\n",
      "Parâmetro: 3 - Fold 5 - MSE: 1.21814\n",
      "Parâmetro: 4 - Fold 5 - MSE: 1.19094\n",
      "Parâmetro: 5 - Fold 5 - MSE: 1.17652\n",
      "Modelo: KNeighborsRegressor - Fold: 3 - MSE: 1.19060\n",
      "\n",
      "Parâmetro: 1 - Fold 1 - MSE: 1.80430\n",
      "Parâmetro: 2 - Fold 1 - MSE: 1.37533\n",
      "Parâmetro: 3 - Fold 1 - MSE: 1.24405\n",
      "Parâmetro: 4 - Fold 1 - MSE: 1.21824\n",
      "Parâmetro: 5 - Fold 1 - MSE: 1.21221\n",
      "Parâmetro: 1 - Fold 2 - MSE: 1.74097\n",
      "Parâmetro: 2 - Fold 2 - MSE: 1.38627\n",
      "Parâmetro: 3 - Fold 2 - MSE: 1.29452\n",
      "Parâmetro: 4 - Fold 2 - MSE: 1.24377\n",
      "Parâmetro: 5 - Fold 2 - MSE: 1.23728\n",
      "Parâmetro: 1 - Fold 3 - MSE: 1.71840\n",
      "Parâmetro: 2 - Fold 3 - MSE: 1.39132\n",
      "Parâmetro: 3 - Fold 3 - MSE: 1.23480\n",
      "Parâmetro: 4 - Fold 3 - MSE: 1.16684\n",
      "Parâmetro: 5 - Fold 3 - MSE: 1.15630\n",
      "Parâmetro: 1 - Fold 4 - MSE: 1.73332\n",
      "Parâmetro: 2 - Fold 4 - MSE: 1.38973\n",
      "Parâmetro: 3 - Fold 4 - MSE: 1.29674\n",
      "Parâmetro: 4 - Fold 4 - MSE: 1.26968\n",
      "Parâmetro: 5 - Fold 4 - MSE: 1.24921\n",
      "Parâmetro: 1 - Fold 5 - MSE: 1.71110\n",
      "Parâmetro: 2 - Fold 5 - MSE: 1.40023\n",
      "Parâmetro: 3 - Fold 5 - MSE: 1.29523\n",
      "Parâmetro: 4 - Fold 5 - MSE: 1.24565\n",
      "Parâmetro: 5 - Fold 5 - MSE: 1.21723\n",
      "Modelo: KNeighborsRegressor - Fold: 4 - MSE: 1.09486\n",
      "\n",
      "Parâmetro: 1 - Fold 1 - MSE: 1.69179\n",
      "Parâmetro: 2 - Fold 1 - MSE: 1.37314\n",
      "Parâmetro: 3 - Fold 1 - MSE: 1.26815\n",
      "Parâmetro: 4 - Fold 1 - MSE: 1.20707\n",
      "Parâmetro: 5 - Fold 1 - MSE: 1.18616\n",
      "Parâmetro: 1 - Fold 2 - MSE: 1.75173\n",
      "Parâmetro: 2 - Fold 2 - MSE: 1.38882\n",
      "Parâmetro: 3 - Fold 2 - MSE: 1.29921\n",
      "Parâmetro: 4 - Fold 2 - MSE: 1.25612\n",
      "Parâmetro: 5 - Fold 2 - MSE: 1.22988\n",
      "Parâmetro: 1 - Fold 3 - MSE: 1.65945\n",
      "Parâmetro: 2 - Fold 3 - MSE: 1.34657\n",
      "Parâmetro: 3 - Fold 3 - MSE: 1.20575\n",
      "Parâmetro: 4 - Fold 3 - MSE: 1.12561\n",
      "Parâmetro: 5 - Fold 3 - MSE: 1.10188\n",
      "Parâmetro: 1 - Fold 4 - MSE: 1.68729\n",
      "Parâmetro: 2 - Fold 4 - MSE: 1.34609\n",
      "Parâmetro: 3 - Fold 4 - MSE: 1.26499\n",
      "Parâmetro: 4 - Fold 4 - MSE: 1.21440\n",
      "Parâmetro: 5 - Fold 4 - MSE: 1.19072\n",
      "Parâmetro: 1 - Fold 5 - MSE: 1.68352\n",
      "Parâmetro: 2 - Fold 5 - MSE: 1.35247\n",
      "Parâmetro: 3 - Fold 5 - MSE: 1.28545\n",
      "Parâmetro: 4 - Fold 5 - MSE: 1.26551\n",
      "Parâmetro: 5 - Fold 5 - MSE: 1.23472\n",
      "Modelo: KNeighborsRegressor - Fold: 5 - MSE: 1.19681\n",
      "\n",
      "Parâmetro: 0 - Fold 1 - MSE: 0.60892\n",
      "Parâmetro: 1 - Fold 1 - MSE: 0.60896\n",
      "Parâmetro: 10 - Fold 1 - MSE: 0.60931\n",
      "Parâmetro: 100 - Fold 1 - MSE: 0.61272\n",
      "Parâmetro: 0 - Fold 2 - MSE: 0.48636\n",
      "Parâmetro: 1 - Fold 2 - MSE: 0.48639\n",
      "Parâmetro: 10 - Fold 2 - MSE: 0.48670\n",
      "Parâmetro: 100 - Fold 2 - MSE: 0.48945\n",
      "Parâmetro: 0 - Fold 3 - MSE: 0.51642\n",
      "Parâmetro: 1 - Fold 3 - MSE: 0.51644\n",
      "Parâmetro: 10 - Fold 3 - MSE: 0.51664\n",
      "Parâmetro: 100 - Fold 3 - MSE: 0.51862\n",
      "Parâmetro: 0 - Fold 4 - MSE: 0.56085\n",
      "Parâmetro: 1 - Fold 4 - MSE: 0.56064\n",
      "Parâmetro: 10 - Fold 4 - MSE: 0.55889\n",
      "Parâmetro: 100 - Fold 4 - MSE: 0.54842\n",
      "Parâmetro: 0 - Fold 5 - MSE: 0.53541\n",
      "Parâmetro: 1 - Fold 5 - MSE: 0.53541\n",
      "Parâmetro: 10 - Fold 5 - MSE: 0.53542\n",
      "Parâmetro: 100 - Fold 5 - MSE: 0.53596\n",
      "Modelo: RidgeRegression - Fold: 1 - MSE: 0.54518\n",
      "\n",
      "Parâmetro: 0 - Fold 1 - MSE: 0.53472\n",
      "Parâmetro: 1 - Fold 1 - MSE: 0.53474\n",
      "Parâmetro: 10 - Fold 1 - MSE: 0.53488\n",
      "Parâmetro: 100 - Fold 1 - MSE: 0.53651\n",
      "Parâmetro: 0 - Fold 2 - MSE: 0.51201\n",
      "Parâmetro: 1 - Fold 2 - MSE: 0.51203\n",
      "Parâmetro: 10 - Fold 2 - MSE: 0.51221\n",
      "Parâmetro: 100 - Fold 2 - MSE: 0.51394\n",
      "Parâmetro: 0 - Fold 3 - MSE: 0.53063\n",
      "Parâmetro: 1 - Fold 3 - MSE: 0.53065\n",
      "Parâmetro: 10 - Fold 3 - MSE: 0.53084\n",
      "Parâmetro: 100 - Fold 3 - MSE: 0.53276\n",
      "Parâmetro: 0 - Fold 4 - MSE: 0.54860\n",
      "Parâmetro: 1 - Fold 4 - MSE: 0.54838\n",
      "Parâmetro: 10 - Fold 4 - MSE: 0.54646\n",
      "Parâmetro: 100 - Fold 4 - MSE: 0.53483\n",
      "Parâmetro: 0 - Fold 5 - MSE: 0.53272\n",
      "Parâmetro: 1 - Fold 5 - MSE: 0.53272\n",
      "Parâmetro: 10 - Fold 5 - MSE: 0.53271\n",
      "Parâmetro: 100 - Fold 5 - MSE: 0.53318\n",
      "Modelo: RidgeRegression - Fold: 2 - MSE: 0.51636\n",
      "\n",
      "Parâmetro: 0 - Fold 1 - MSE: 0.55090\n",
      "Parâmetro: 1 - Fold 1 - MSE: 0.55066\n",
      "Parâmetro: 10 - Fold 1 - MSE: 0.54867\n",
      "Parâmetro: 100 - Fold 1 - MSE: 0.53691\n",
      "Parâmetro: 0 - Fold 2 - MSE: 0.51825\n",
      "Parâmetro: 1 - Fold 2 - MSE: 0.51822\n",
      "Parâmetro: 10 - Fold 2 - MSE: 0.51802\n",
      "Parâmetro: 100 - Fold 2 - MSE: 0.51722\n",
      "Parâmetro: 0 - Fold 3 - MSE: 0.62958\n",
      "Parâmetro: 1 - Fold 3 - MSE: 0.62964\n",
      "Parâmetro: 10 - Fold 3 - MSE: 0.63016\n",
      "Parâmetro: 100 - Fold 3 - MSE: 0.63469\n",
      "Parâmetro: 0 - Fold 4 - MSE: 0.52796\n",
      "Parâmetro: 1 - Fold 4 - MSE: 0.52797\n",
      "Parâmetro: 10 - Fold 4 - MSE: 0.52809\n",
      "Parâmetro: 100 - Fold 4 - MSE: 0.52947\n",
      "Parâmetro: 0 - Fold 5 - MSE: 0.50108\n",
      "Parâmetro: 1 - Fold 5 - MSE: 0.50111\n",
      "Parâmetro: 10 - Fold 5 - MSE: 0.50139\n",
      "Parâmetro: 100 - Fold 5 - MSE: 0.50400\n",
      "Modelo: RidgeRegression - Fold: 3 - MSE: 0.55655\n",
      "\n",
      "Parâmetro: 0 - Fold 1 - MSE: 0.51410\n",
      "Parâmetro: 1 - Fold 1 - MSE: 0.51411\n",
      "Parâmetro: 10 - Fold 1 - MSE: 0.51424\n",
      "Parâmetro: 100 - Fold 1 - MSE: 0.51598\n",
      "Parâmetro: 0 - Fold 2 - MSE: 0.54363\n",
      "Parâmetro: 1 - Fold 2 - MSE: 0.54362\n",
      "Parâmetro: 10 - Fold 2 - MSE: 0.54352\n",
      "Parâmetro: 100 - Fold 2 - MSE: 0.54387\n",
      "Parâmetro: 0 - Fold 3 - MSE: 0.55551\n",
      "Parâmetro: 1 - Fold 3 - MSE: 0.55539\n",
      "Parâmetro: 10 - Fold 3 - MSE: 0.55444\n",
      "Parâmetro: 100 - Fold 3 - MSE: 0.55006\n",
      "Parâmetro: 0 - Fold 4 - MSE: 0.51305\n",
      "Parâmetro: 1 - Fold 4 - MSE: 0.51307\n",
      "Parâmetro: 10 - Fold 4 - MSE: 0.51331\n",
      "Parâmetro: 100 - Fold 4 - MSE: 0.51576\n",
      "Parâmetro: 0 - Fold 5 - MSE: 0.51661\n",
      "Parâmetro: 1 - Fold 5 - MSE: 0.51663\n",
      "Parâmetro: 10 - Fold 5 - MSE: 0.51680\n",
      "Parâmetro: 100 - Fold 5 - MSE: 0.51897\n",
      "Modelo: RidgeRegression - Fold: 4 - MSE: 0.52516\n",
      "\n",
      "Parâmetro: 0 - Fold 1 - MSE: 0.51920\n",
      "Parâmetro: 1 - Fold 1 - MSE: 0.51921\n",
      "Parâmetro: 10 - Fold 1 - MSE: 0.51932\n",
      "Parâmetro: 100 - Fold 1 - MSE: 0.52056\n",
      "Parâmetro: 0 - Fold 2 - MSE: 0.56302\n",
      "Parâmetro: 1 - Fold 2 - MSE: 0.56301\n",
      "Parâmetro: 10 - Fold 2 - MSE: 0.56292\n",
      "Parâmetro: 100 - Fold 2 - MSE: 0.56290\n",
      "Parâmetro: 0 - Fold 3 - MSE: 0.53374\n",
      "Parâmetro: 1 - Fold 3 - MSE: 0.53375\n",
      "Parâmetro: 10 - Fold 3 - MSE: 0.53386\n",
      "Parâmetro: 100 - Fold 3 - MSE: 0.53501\n",
      "Parâmetro: 0 - Fold 4 - MSE: 0.53807\n",
      "Parâmetro: 1 - Fold 4 - MSE: 0.53795\n",
      "Parâmetro: 10 - Fold 4 - MSE: 0.53691\n",
      "Parâmetro: 100 - Fold 4 - MSE: 0.53040\n",
      "Parâmetro: 0 - Fold 5 - MSE: 0.51364\n",
      "Parâmetro: 1 - Fold 5 - MSE: 0.51366\n",
      "Parâmetro: 10 - Fold 5 - MSE: 0.51384\n",
      "Parâmetro: 100 - Fold 5 - MSE: 0.51566\n",
      "Modelo: RidgeRegression - Fold: 5 - MSE: 0.50769\n",
      "\n",
      "\n",
      "\n",
      "Parâmetro: 0 - Fold 1 - MSE: 0.54443\n",
      "Parâmetro: 1 - Fold 1 - MSE: 0.54443\n",
      "Parâmetro: 10 - Fold 1 - MSE: 0.54448\n",
      "Parâmetro: 100 - Fold 1 - MSE: 0.54518\n",
      "Parâmetro: 0 - Fold 2 - MSE: 0.51525\n",
      "Parâmetro: 1 - Fold 2 - MSE: 0.51526\n",
      "Parâmetro: 10 - Fold 2 - MSE: 0.51533\n",
      "Parâmetro: 100 - Fold 2 - MSE: 0.51636\n",
      "Parâmetro: 0 - Fold 3 - MSE: 0.55665\n",
      "Parâmetro: 1 - Fold 3 - MSE: 0.55664\n",
      "Parâmetro: 10 - Fold 3 - MSE: 0.55657\n",
      "Parâmetro: 100 - Fold 3 - MSE: 0.55655\n",
      "Parâmetro: 0 - Fold 4 - MSE: 0.52646\n",
      "Parâmetro: 1 - Fold 4 - MSE: 0.52632\n",
      "Parâmetro: 10 - Fold 4 - MSE: 0.52516\n",
      "Parâmetro: 100 - Fold 4 - MSE: 0.51734\n",
      "Parâmetro: 0 - Fold 5 - MSE: 0.50528\n",
      "Parâmetro: 1 - Fold 5 - MSE: 0.50531\n",
      "Parâmetro: 10 - Fold 5 - MSE: 0.50554\n",
      "Parâmetro: 100 - Fold 5 - MSE: 0.50769\n",
      "\n",
      "\n",
      "Melhor modelo: RidgeRegression\n",
      "Melhor valor do parâmetro: 100\n",
      "MSE no conjunto de teste: 0.53104\n"
     ]
    }
   ],
   "source": [
    "n_splits = 5\n",
    "kfold = KFold(n_splits, SEED)\n",
    "\n",
    "# Configuração dos parâmetros para cada modelo\n",
    "config = {\n",
    "    KNeighborsRegressor: list(range(1, 6)),\n",
    "    RidgeRegression: [0, 1, 10, 100]\n",
    "}\n",
    "\n",
    "# Inicializa um dicionário para armazenar os erros de cada modelo\n",
    "errors = {\n",
    "    class_: np.zeros(n_splits) for class_ in config.keys()\n",
    "}\n",
    "\n",
    "print('Iniciando a validação cruzada...')\n",
    "# Para cada classe de modelo e seus parâmetros\n",
    "for class_, params in config.items():\n",
    "    # Para cada divisão da validação cruzada\n",
    "    for i, (X_train_, X_val, y_train_, y_val) in enumerate(kfold.split(X_train, y_train)):\n",
    "        # Cria um objeto CrossValidation para o modelo atual\n",
    "        cv = CrossValidation(class_, params, n_splits, SEED, log_results=True)\n",
    "        cv.fit(X_train_, y_train_)\n",
    "        # Obtém o melhor modelo e ajusta aos dados de treino\n",
    "        best_model = cv.best_model.fit(X_train_, y_train_)\n",
    "        # Faz a previsão para os dados de validação\n",
    "        y_pred = best_model.predict(X_val)\n",
    "         # Calcula o erro quadrático médio da previsão\n",
    "        error = mse(y_val, y_pred)\n",
    "         # Armazena o erro no dicionário de erros\n",
    "        errors[class_][i] = error\n",
    "        print(f'Modelo: {class_.__name__} - Fold: {i + 1} - MSE: {error:.5f}\\n')\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Obtém a classe de modelo que teve o menor erro médio\n",
    "best_class = min(errors, key=lambda k: errors[k].mean())\n",
    "cv = CrossValidation(\n",
    "    best_class, config[best_class], n_splits, SEED, log_results=True\n",
    ").fit(X_train, y_train)\n",
    "# Obtém o melhor modelo e ajusta aos dados de treino\n",
    "best_model = cv.best_model.fit(X_train, y_train)\n",
    "# Faz a previsão para os dados de teste\n",
    "y_pred = best_model.predict(X_test)\n",
    "# Calcula o erro quadrático médio da previsão\n",
    "error = mse(y_test, y_pred)\n",
    "\n",
    "print(f'\\n\\nMelhor modelo: {best_class.__name__}')\n",
    "print(f'Melhor valor do parâmetro: {cv.best_parameter}')\n",
    "print(f'MSE no conjunto de teste: {error:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad26c12d",
   "metadata": {},
   "source": [
    "Neste código comparamos o KNN (K-Nearest Neighbors) e a Regressão Linear com regularização L2, variando os parâmetros $k$ e $c$ respectivamente, e selecionamos os melhores hiperparâmetros para cada modelo com base no erro quadrático médio do conjunto de validação.\n",
    "\n",
    "A partir dos resultados da validação cruzada aninhada, foi possível identificar que a regressão com regularização L2 teve um melhor desempenho em média, com um valor de $c=100$ como o melhor hiperparâmetro. O MSE obtido no conjunto de teste para esse modelo foi de $\\approx 0.531$.\n",
    "\n",
    "A seleção do modelo Ridge Regression sobre o k-NN sugere que a regularização $L2$ foi benéfica para lidar com a complexidade do modelo e prevenir o overfitting, levando a uma melhor generalização nos dados de teste."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f268c40-0ccb-4420-9100-4cb669d98521",
   "metadata": {},
   "source": [
    "# Exercício de \"papel e caneta\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf3e1ec-14cd-4bf8-bea4-20c06de871f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "**1.** Nas nota de aula, derivamos o \"dilema viés-variância\" calculando o MSE esperado entre a função alvo de aprendizado $f$ e a predição do nosso modelo $h_{\\mathcal{D}}$:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}_{x, \\mathcal{D}} \n",
    "    \\left[ \n",
    "        \\left( \n",
    "        h_{\\mathcal{D}}(x) - f\\left(x\\right) \n",
    "        \\right)^2\n",
    "    \\right] =\n",
    "\\mathbb{E}_{x}[\\underbrace{\\textrm{Var}_{\\mathcal{D}}[\n",
    "        h_{\\mathcal{D}}(x)]}_{\\text{ Variância} }] + \\mathbb{E}_{x} [ (\\underbrace{\\mathbb{E}_{\\mathcal{D}}[\n",
    "        h_{\\mathcal{D}}(x) - f\\left(x\\right)]  }_{\\text{Viés}})^2] \n",
    "    ].\n",
    "$$\n",
    "\n",
    "Com isso em mente, adapte nossa derivação para o caso em que as respostas de teste $f(x)$ são corrompidas por um ruído aditivo aleatório $\\epsilon$ com média zero, i.e., observamos $f^\\prime(x) = f(x) + \\epsilon$. Mais concretamente, trabalhe a seguinte esperança para derivar uma decomposição similar à da nota de aula:\n",
    "$$\n",
    "\\mathbb{E}_{x, \\epsilon, \\mathcal{D}} \n",
    "    \\left[\n",
    "        \\left( \n",
    "        h_{\\mathcal{D}}(x) - f^\\prime\\left(x\\right)\n",
    "        \\right)^2\n",
    "    \\right].\n",
    "$$\n",
    "\n",
    "Compare a diferença entre a decomposição que você obteve e a da nota de aula.\n",
    "\n",
    "Dica: sua decomposição deve se diferenciar da acima em apenas um termo aditivo, que envolve uma esperança sobre $x$ e $y$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e3022c-95e5-4881-a10b-b6e05c39c2ac",
   "metadata": {},
   "source": [
    "### Resposta:\n",
    "\n",
    "Pelas notas de aula, vimos que:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbb{E}_{x, \\mathcal{D}}\\left[\\left(h_{\\mathcal{D}}(x)-f'(x) \\right)^2\\right] & =\\mathbb{E}_{x, \\mathcal{D}}\\left[h_{\\mathcal{D}}(x)^2+f'(x) ^2-2 h_{\\mathcal{D}}(x) f'(x) \\right] \\\\\n",
    "& =\\mathbb{E}_x\\left[\\mathbb{E}_{\\mathcal{D}}\\left[h_{\\mathcal{D}}(x)^2\\right]\\right]+\\mathbb{E}_x\\left[f'(x) ^2-2 \\mathbb{E}_{\\mathcal{D}}\\left[h_{\\mathcal{D}}(x)\\right] f'(x) \\right]\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Ao somar $\\mathbb{E}_{x, \\mathcal{D}}\\left[h_{\\mathcal{D}}(x)\\right]^2-\\mathbb{E}_{x, \\mathcal{D}}\\left[h_{\\mathcal{D}}(x)\\right]^2$ à última linha para obter:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbb{E}_{x, \\mathcal{D}}\\left[\\left(h_{\\mathcal{D}}(x)-f'(x) \\right)^2\\right] & = \\underbrace{\\mathbb{E}_x\\left[\\mathbb{E}_{\\mathcal{D}}\\left[h_{\\mathcal{D}}(x)^2\\right] -\\mathbb{E}_{\\mathcal{D}}\\left[h_{\\mathcal{D}}(x)\\right]^2\\right]}_{(1)}+\\underbrace{\\mathbb{E}_{x}\\left[\\mathbb{E}_{\\mathcal{D}}\\left[h_{\\mathcal{D}}(x)\\right]^2+ f'(x)^2 - 2 \\mathbb{E}_\\mathcal{D}\\left[ h_{\\mathcal{D}}(x)\\right] f'(x) \\right]}_{\\text{(2)}} \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Sabendo que a fórmula da variância é $Var(X) = \\mathbb{E}[X^2] - \\mathbb{E}[X]^2$, temos que (1) é:\n",
    "\n",
    "$$\\mathbb{E}_x\\left[\\mathbb{E}_{\\mathcal{D}}\\left[h_{\\mathcal{D}}(x)^2\\right] -\\mathbb{E}_{\\mathcal{D}}\\left[h_{\\mathcal{D}}(x)\\right]^2\\right] = \\mathbb{E}_x\\left[ Var_{\\mathcal{D}}[h_{\\mathcal{D}}(x)] \\right]$$\n",
    "\n",
    "Agora vamos expandir o termo $(2)$ que depende de $f'(x)$: \n",
    "\n",
    "$$\\mathbb{E}_{x}\\left[\\mathbb{E}_{\\mathcal{D}}\\left[h_{\\mathcal{D}}(x)\\right]^2+ f'(x)^2 - 2 \\mathbb{E}_\\mathcal{D}\\left[ h_{\\mathcal{D}}(x)\\right] f'(x) \\right] = \\mathbb{E}_{x}\\left[\\mathbb{E}_{\\mathcal{D}}\\left[h_{\\mathcal{D}}(x)\\right]^2\\right] + \\underbrace{\\mathbb{E}_{x}\\left[f'(x)^2 \\right]}_{(3)} - 2  \\underbrace{\\mathbb{E}_{x}  \\left[\\mathbb{E}_\\mathcal{D}\\left[ h_{\\mathcal{D}}(x)\\right] f'(x)\\right]}_{(4)}$$\n",
    "\n",
    "Desenvolvendo $(3)$:\n",
    "\n",
    "$$\\mathbb{E}_{x}\\left[f'(x)^2 \\right] = \\mathbb{E}_{x}\\left[(f(x) + \\epsilon)^2 \\right] = \\mathbb{E}_{x}\\left[f(x)^2 + 2 f(x) \\epsilon + \\epsilon^2 \\right]$$\n",
    "\n",
    "$$ = \\mathbb{E}_{x}\\left[f(x)^2 \\right] + 2\\epsilon \\underbrace{\\mathbb{E}_{x}\\left[f(x) \\right]}_{0} + \\mathbb{E}_{x}\\left[\\epsilon^2 \\right]= \\mathbb{E}_{x}\\left[f(x)^2 \\right] + \\underbrace{\\mathbb{E}_{x}\\left[\\epsilon^2 \\right]}_{\\sigma^2}$$\n",
    "\n",
    "Novamente pela fórmula de variância, temos que:\n",
    "$$\\mathbb{E}_{x} Var(\\epsilon) = \\mathbb{E}_{x} \\left[ \\mathbb{E}_{\\epsilon} \\left[ \\epsilon^2 \\right] - \\mathbb{E}_{\\epsilon} \\left[ \\epsilon \\right]^2 \\right] = \\mathbb{E}_{x} \\left[ \\sigma^2 - 0 \\right] = \\sigma^2$$\n",
    "\n",
    "Então, temos que $\\mathbb{E}_{x}\\left[f'(x)^2 \\right] = \\mathbb{E}_{x}\\left[f(x)^2 \\right] + \\mathbb{E}_{x} Var(\\epsilon)$.\n",
    "\n",
    "Por fim, desenvolvendo $(4)$:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbb{E}_{x}  \\left[\\mathbb{E}_\\mathcal{D}\\left[ h_{\\mathcal{D}}(x)\\right] f'(x)\\right] & = \\mathbb{E}_{x}  \\left[\\mathbb{E}_\\mathcal{D}\\left[ h_{\\mathcal{D}}(x)\\right] (f(x) + \\epsilon)\\right] \\\\\n",
    "& = \\mathbb{E}_{x}  \\left[\\mathbb{E}_\\mathcal{D}\\left[ h_{\\mathcal{D}}(x)\\right] f(x)\\right] + \\mathbb{E}_{x}  \\left[\\mathbb{E}_\\mathcal{D}\\left[ h_{\\mathcal{D}}(x)\\right] \\epsilon\\right] \\\\\n",
    "& = \\mathbb{E}_{x}  \\left[\\mathbb{E}_\\mathcal{D}\\left[ h_{\\mathcal{D}}(x)\\right] f(x)\\right] \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Pois, $\\mathbb{E}{x} \\left[\\mathbb{E}_\\mathcal{D}\\left[ h_{\\mathcal{D}}(x)\\right] \\epsilon\\right] = \\mathbb{E}_\\mathcal{D}\\left[ h_{\\mathcal{D}}(x)\\right] \\underbrace{\\mathbb{E}{x}[\\epsilon]}_{0} = 0$\n",
    "\n",
    "\n",
    "Substituindo $(3)$ e $(4)$ em $(2)$, temos que:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbb{E}_{x}\\left[\\mathbb{E}_{\\mathcal{D}}\\left[h_{\\mathcal{D}}(x)\\right]^2+ f'(x)^2 - 2 \\mathbb{E}_\\mathcal{D}\\left[ h_{\\mathcal{D}}(x)\\right] f'(x) \\right] & = \\mathbb{E}_{x}\\left[\\mathbb{E}_{\\mathcal{D}}\\left[h_{\\mathcal{D}}(x)\\right]^2\\right] + \\mathbb{E}_{x}\\left[f(x)^2 \\right] + \\mathbb{E}_{x} Var(\\epsilon) - 2 \\mathbb{E}_{x}  \\left[\\mathbb{E}_\\mathcal{D}\\left[ h_{\\mathcal{D}}(x)\\right] f(x)\\right] \\\\\n",
    "& = \\mathbb{E}_x\\left[\\left(\\mathbb{E}_{\\mathcal{D}}\\left[h_{\\mathcal{D}}(x)-f(x)\\right]\\right)^2\\right] + \\mathbb{E}_{x} Var(\\epsilon)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "E portanto, \n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbb{E}_{x, \\mathcal{D}}\\left[\\left(h_{\\mathcal{D}}(x)-f'(x) \\right)^2\\right] & = (1) + (2)\\\\\n",
    "& = \\underbrace{\\mathbb{E}_x\\left[ Var_{\\mathcal{D}}[h_{\\mathcal{D}}(x)] \\right]}_{\\text{Variância}} + \\underbrace{\\mathbb{E}_x\\left[\\left(\\mathbb{E}_{\\mathcal{D}}\\left[h_{\\mathcal{D}}(x)-f(x)\\right]\\right)^2\\right]}_{Viés} + \\underbrace{\\mathbb{E}_{x} Var(\\epsilon)}_{\\text{Ruído}}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Diferentemente da decomposição original, temos um termo adicional que representa o ruído presente nos dados, representado por $\\mathbb{E}_{x} Var(\\epsilon)$. Na decomposição original, ao usar apenas $f(x)$, obtínhamos:\n",
    "\n",
    "$$\\mathbb{E}_{x, \\mathcal{D}}\\left[\\left(h_{\\mathcal{D}}(x)-f(x)\\right)^2\\right]=\\mathbb{E}_x[\\underbrace{\\operatorname{Var}_{\\mathcal{D}}\\left[h_{\\mathcal{D}}(x)\\right]}_{\\text {Variância }}]+\\mathbb{E}_x[(\\underbrace{\\mathbb{E}_{\\mathcal{D}}\\left[h_{\\mathcal{D}}(x)-f(x)\\right]}_{\\text {Viés }})^2]$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
